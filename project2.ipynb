{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e50c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/kali/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/kali/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#load data \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "x_train_df = pd.read_csv('data_reviews/x_train.csv')\n",
    "y_train_df = pd.read_csv('data_reviews/y_train.csv')\n",
    "\n",
    "tr_text_list = x_train_df['text'].values.tolist()\n",
    "print(len(tr_text_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f887a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['it', 'feel', 'poorli', 'construct', 'the', 'menu', 'are', 'difficult', 'to', 'navig', 'and', 'the', 'button', 'are', 'so', 'recess', 'that', 'it', 'is', 'difficult', 'to', 'push', 'them']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Build bag of words \n",
    "-tokenization\n",
    "-set all to lowercase\n",
    "-remove punctuations\n",
    "-remove stopwords\n",
    "\"\"\"\n",
    "\n",
    "#tokenization\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer()\n",
    "word_count_vector = cv.fit_transform(tr_text_list)\n",
    "\n",
    "\n",
    "\n",
    "# print(\"Number of features: \", len(x.toarray()[0]))\n",
    "# print(count_vectorizer.get_feature_names())\n",
    "# print(x.toarray())\n",
    "# pd.DataFrame(x.toarray(), columns=count_vectorizer.get_feature_names())\n",
    "\n",
    "appos = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who're\" : \"who are\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'll\":\" will\",\n",
    "\"didn't\": \"did not\"\n",
    "}\n",
    "\n",
    "# Preprocess Data\n",
    "def preprocess(review_arr):\n",
    "    processed = []\n",
    "\n",
    "    # case characters by converting them all to lowercase\n",
    "    for text in review_arr:\n",
    "        processed.append(text.lower())\n",
    "\n",
    "    # negation handling by converting apostrophes to standard lexicon \n",
    "    negation = []\n",
    "    for text in processed:\n",
    "        words = text.split()\n",
    "        reformed = [appos[word] if word in appos else word for word in words]\n",
    "        reformed = \" \".join(reformed)\n",
    "        negation.append(reformed)\n",
    "\n",
    "    # tokenize data by converting text to tokens\n",
    "    tokenized = []\n",
    "    for text in negation:\n",
    "        tokenized.append(word_tokenize(text))\n",
    "\n",
    "    # remove stopwords from sentences (words that are most commonly occurring, but not\n",
    "    # relevant in the context of the data)\n",
    "    # we use english stopwords here, which may not be relevant in the context of foreign words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    for text in tokenized:\n",
    "        text = [i for i in text if not i in stop_words]\n",
    "\n",
    "    # remove stand-alone punctuation\n",
    "    stripped = []\n",
    "    for text in tokenized:\n",
    "        words = [word for word in text if word.isalpha()]\n",
    "        stripped.append(words)\n",
    "    #return stripped\n",
    "    # stemming/lemmatization finds the base or dictionary form of the word known as the lemma\n",
    "    # using vocabulary and morphological analysis\n",
    "    # use gensim package -- which takes into account part-of-speech as well.\n",
    "    lemmas = []\n",
    "    porter = PorterStemmer()\n",
    "    for text in stripped:\n",
    "        lemmafied = []\n",
    "        for t in text:\n",
    "            lemmafied.append(porter.stem(t))\n",
    "        lemmas.append(lemmafied)\n",
    "\n",
    "    return lemmas\n",
    "  \n",
    "p = preprocess(tr_text_list)\n",
    "print(p[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1c9f67",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2400, 3417) (600, 3417)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# feature transform training set\n",
    "x_tr_pre = preprocess(tr_text_list)\n",
    "x_tr = []\n",
    "for text in x_tr_pre:\n",
    "    sentence = \" \".join(text)\n",
    "    x_tr.append(sentence)\n",
    "x_train = vectorizer.fit_transform(x_tr)\n",
    "\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "\n",
    "\n",
    "# feature transform testing set\n",
    "x_test_df = pd.read_csv('data_reviews/x_test.csv')\n",
    "te_text_list = x_test_df['text'].values.tolist()\n",
    "x_te_pre = preprocess(te_text_list)\n",
    "x_te = [] \n",
    "for text in x_te_pre:\n",
    "    sentence = \" \".join(text)\n",
    "    x_te.append(sentence)\n",
    "x_test = vectorizer.transform(x_te)\n",
    "print(x_train.shape, x_test.shape)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71a9bfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: \n",
      "0.8195833333333333\n",
      "STANDARD DEVIATIONS\n",
      "[0.03333333 0.02637207 0.02985497 0.02727815 0.02162657 0.02520747\n",
      " 0.01475494 0.0247347  0.00857969 0.02496525 0.01065559 0.02202429\n",
      " 0.01334635 0.02190573 0.01369306 0.01719981 0.016383   0.01481366\n",
      " 0.01689428 0.01790213]\n",
      "STANDARD DEVIATION FOR BEST SCORE:\n",
      "0.027278145505554862\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'C': 4.641588833612778, 'penalty': 'l2'}</td>\n",
       "      <td>0.819583</td>\n",
       "      <td>0.027278</td>\n",
       "      <td>0.845833</td>\n",
       "      <td>0.835417</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>{'C': 21.544346900318832, 'penalty': 'l2'}</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.025207</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.837500</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.809583</td>\n",
       "      <td>0.026372</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>{'C': 4.641588833612778, 'penalty': 'l1'}</td>\n",
       "      <td>0.801667</td>\n",
       "      <td>0.029855</td>\n",
       "      <td>0.810417</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.837500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.806250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>{'C': 464.15888336127773, 'penalty': 'l2'}</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.024965</td>\n",
       "      <td>0.806250</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.795833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>{'C': 1.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.814583</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.722917</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.802083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>{'C': 21.544346900318832, 'penalty': 'l1'}</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.021627</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>9</td>\n",
       "      <td>{'C': 2154.4346900318824, 'penalty': 'l2'}</td>\n",
       "      <td>0.772500</td>\n",
       "      <td>0.022024</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>{'C': 100.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.766250</td>\n",
       "      <td>0.014755</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.775000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11</td>\n",
       "      <td>{'C': 10000.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.021906</td>\n",
       "      <td>0.793750</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.731250</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.772917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>{'C': 46415.888336127726, 'penalty': 'l2'}</td>\n",
       "      <td>0.762083</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.764583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13</td>\n",
       "      <td>{'C': 464.15888336127773, 'penalty': 'l1'}</td>\n",
       "      <td>0.756667</td>\n",
       "      <td>0.008580</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.758333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14</td>\n",
       "      <td>{'C': 10000.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.013346</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.745833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>15</td>\n",
       "      <td>{'C': 215443.46900318822, 'penalty': 'l2'}</td>\n",
       "      <td>0.753750</td>\n",
       "      <td>0.014814</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.756250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>{'C': 2154.4346900318824, 'penalty': 'l1'}</td>\n",
       "      <td>0.752500</td>\n",
       "      <td>0.010656</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>17</td>\n",
       "      <td>{'C': 1000000.0, 'penalty': 'l2'}</td>\n",
       "      <td>0.740833</td>\n",
       "      <td>0.017902</td>\n",
       "      <td>0.762500</td>\n",
       "      <td>0.745833</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.747917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>{'C': 1000000.0, 'penalty': 'l1'}</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.016894</td>\n",
       "      <td>0.768750</td>\n",
       "      <td>0.735417</td>\n",
       "      <td>0.716667</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.735417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>19</td>\n",
       "      <td>{'C': 46415.888336127726, 'penalty': 'l1'}</td>\n",
       "      <td>0.739583</td>\n",
       "      <td>0.013693</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.752083</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20</td>\n",
       "      <td>{'C': 215443.46900318822, 'penalty': 'l1'}</td>\n",
       "      <td>0.738750</td>\n",
       "      <td>0.016383</td>\n",
       "      <td>0.764583</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.725000</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.718750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score                                      params  \\\n",
       "3                 1   {'C': 4.641588833612778, 'penalty': 'l2'}   \n",
       "5                 2  {'C': 21.544346900318832, 'penalty': 'l2'}   \n",
       "1                 3                 {'C': 1.0, 'penalty': 'l2'}   \n",
       "2                 4   {'C': 4.641588833612778, 'penalty': 'l1'}   \n",
       "7                 5               {'C': 100.0, 'penalty': 'l2'}   \n",
       "9                 6  {'C': 464.15888336127773, 'penalty': 'l2'}   \n",
       "0                 7                 {'C': 1.0, 'penalty': 'l1'}   \n",
       "4                 8  {'C': 21.544346900318832, 'penalty': 'l1'}   \n",
       "11                9  {'C': 2154.4346900318824, 'penalty': 'l2'}   \n",
       "6                10               {'C': 100.0, 'penalty': 'l1'}   \n",
       "13               11             {'C': 10000.0, 'penalty': 'l2'}   \n",
       "15               12  {'C': 46415.888336127726, 'penalty': 'l2'}   \n",
       "8                13  {'C': 464.15888336127773, 'penalty': 'l1'}   \n",
       "12               14             {'C': 10000.0, 'penalty': 'l1'}   \n",
       "17               15  {'C': 215443.46900318822, 'penalty': 'l2'}   \n",
       "10               16  {'C': 2154.4346900318824, 'penalty': 'l1'}   \n",
       "19               17           {'C': 1000000.0, 'penalty': 'l2'}   \n",
       "18               18           {'C': 1000000.0, 'penalty': 'l1'}   \n",
       "14               19  {'C': 46415.888336127726, 'penalty': 'l1'}   \n",
       "16               20  {'C': 215443.46900318822, 'penalty': 'l1'}   \n",
       "\n",
       "    mean_test_score  std_test_score  split0_test_score  split1_test_score  \\\n",
       "3          0.819583        0.027278           0.845833           0.835417   \n",
       "5          0.810417        0.025207           0.829167           0.837500   \n",
       "1          0.809583        0.026372           0.833333           0.808333   \n",
       "2          0.801667        0.029855           0.810417           0.827083   \n",
       "7          0.793333        0.024735           0.814583           0.818750   \n",
       "9          0.779167        0.024965           0.806250           0.795833   \n",
       "0          0.777083        0.033333           0.814583           0.789583   \n",
       "4          0.772500        0.021627           0.772917           0.804167   \n",
       "11         0.772500        0.022024           0.800000           0.787500   \n",
       "6          0.766250        0.014755           0.772917           0.785417   \n",
       "13         0.765000        0.021906           0.793750           0.777083   \n",
       "15         0.762083        0.017200           0.785417           0.772917   \n",
       "8          0.756667        0.008580           0.758333           0.770833   \n",
       "12         0.755000        0.013346           0.750000           0.781250   \n",
       "17         0.753750        0.014814           0.775000           0.762500   \n",
       "10         0.752500        0.010656           0.756250           0.770833   \n",
       "19         0.740833        0.017902           0.762500           0.745833   \n",
       "18         0.740000        0.016894           0.768750           0.735417   \n",
       "14         0.739583        0.013693           0.754167           0.752083   \n",
       "16         0.738750        0.016383           0.764583           0.737500   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  \n",
       "3            0.785417           0.787500           0.843750  \n",
       "5            0.775000           0.785417           0.825000  \n",
       "1            0.772917           0.789583           0.843750  \n",
       "2            0.766667           0.766667           0.837500  \n",
       "7            0.760417           0.766667           0.806250  \n",
       "9            0.747917           0.750000           0.795833  \n",
       "0            0.722917           0.756250           0.802083  \n",
       "4            0.747917           0.750000           0.787500  \n",
       "11           0.741667           0.752083           0.781250  \n",
       "6            0.750000           0.747917           0.775000  \n",
       "13           0.731250           0.750000           0.772917  \n",
       "15           0.735417           0.752083           0.764583  \n",
       "8            0.745833           0.750000           0.758333  \n",
       "12           0.745833           0.752083           0.745833  \n",
       "17           0.733333           0.741667           0.756250  \n",
       "10           0.745833           0.739583           0.750000  \n",
       "19           0.708333           0.739583           0.747917  \n",
       "18           0.716667           0.743750           0.735417  \n",
       "14           0.733333           0.741667           0.716667  \n",
       "16           0.725000           0.747917           0.718750  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear')\n",
    "# Grid Search for Hyperparameters\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 6, 10)\n",
    "hyperparams = dict(C=C, penalty=penalty)\n",
    "clf_LR = GridSearchCV(logreg, hyperparams, cv=5, verbose=0)\n",
    "clf_LR.fit(x_train, np.ravel(y_train_df))\n",
    "print(\"BEST SCORE: \")\n",
    "print(clf_LR.best_score_)\n",
    "print(\"STANDARD DEVIATIONS\")\n",
    "print(clf_LR.cv_results_['std_test_score'])\n",
    "print(\"STANDARD DEVIATION FOR BEST SCORE:\")\n",
    "print(clf_LR.cv_results_['std_test_score'][clf_LR.best_index_])\n",
    "\n",
    "\n",
    "df1= pd.DataFrame(clf_LR.cv_results_)\n",
    "df1[['rank_test_score','params', 'mean_test_score', 'std_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']].sort_values('rank_test_score')\n",
    "\n",
    "# pivot = pd.pivot_table(pd.DataFrame(clf.cv_results_), values='mean_test_score', index='param_C', columns='param_penalty')\n",
    "# ax = sns.heatmap(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5bed82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LR prediction\n",
    "\n",
    "yproba1_test = clf_LR.predict_proba(x_test)[:, 1]\n",
    "np.savetxt('yproba1_test.txt', yproba1_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9618fc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (120) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: \n",
      "0.81875\n",
      "STANDARD DEVIATIONS\n",
      "[0.         0.00083333 0.0247347  0.02867442 0.         0.\n",
      " 0.05513557 0.02318405 0.         0.0875     0.02674468 0.02504856\n",
      " 0.         0.01       0.02776389 0.02715056]\n",
      "STANDARD DEVIATION FOR BEST SCORE:\n",
      "0.026744677559802022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 1.0}</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.026745</td>\n",
       "      <td>0.839583</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.789583</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.852083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 1.0}</td>\n",
       "      <td>0.818750</td>\n",
       "      <td>0.027764</td>\n",
       "      <td>0.845833</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>0.845833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 1.0}</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.024735</td>\n",
       "      <td>0.839583</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.785417</td>\n",
       "      <td>0.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 0.1}</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>0.023184</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.804167</td>\n",
       "      <td>0.779167</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.841667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 0.1}</td>\n",
       "      <td>0.803750</td>\n",
       "      <td>0.025049</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.822917</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.814583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 0.1}</td>\n",
       "      <td>0.801250</td>\n",
       "      <td>0.028674</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>7</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 0.1}</td>\n",
       "      <td>0.799167</td>\n",
       "      <td>0.027151</td>\n",
       "      <td>0.827083</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.777083</td>\n",
       "      <td>0.808333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 1.0}</td>\n",
       "      <td>0.597917</td>\n",
       "      <td>0.055136</td>\n",
       "      <td>0.658333</td>\n",
       "      <td>0.668750</td>\n",
       "      <td>0.556250</td>\n",
       "      <td>0.572917</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 10.0}</td>\n",
       "      <td>0.543750</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 10.0}</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.525000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 10.0}</td>\n",
       "      <td>0.500417</td>\n",
       "      <td>0.000833</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.502083</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>{'activation': 'identity', 'alpha': 100.0}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 100.0}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>{'activation': 'logistic', 'alpha': 10.0}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>12</td>\n",
       "      <td>{'activation': 'relu', 'alpha': 100.0}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>{'activation': 'tanh', 'alpha': 100.0}</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score                                      params  \\\n",
       "10                1        {'activation': 'relu', 'alpha': 1.0}   \n",
       "14                1        {'activation': 'tanh', 'alpha': 1.0}   \n",
       "2                 3    {'activation': 'identity', 'alpha': 1.0}   \n",
       "7                 4    {'activation': 'logistic', 'alpha': 0.1}   \n",
       "11                5        {'activation': 'relu', 'alpha': 0.1}   \n",
       "3                 6    {'activation': 'identity', 'alpha': 0.1}   \n",
       "15                7        {'activation': 'tanh', 'alpha': 0.1}   \n",
       "6                 8    {'activation': 'logistic', 'alpha': 1.0}   \n",
       "9                 9       {'activation': 'relu', 'alpha': 10.0}   \n",
       "13               10       {'activation': 'tanh', 'alpha': 10.0}   \n",
       "1                11   {'activation': 'identity', 'alpha': 10.0}   \n",
       "0                12  {'activation': 'identity', 'alpha': 100.0}   \n",
       "4                12  {'activation': 'logistic', 'alpha': 100.0}   \n",
       "5                12   {'activation': 'logistic', 'alpha': 10.0}   \n",
       "8                12      {'activation': 'relu', 'alpha': 100.0}   \n",
       "12               12      {'activation': 'tanh', 'alpha': 100.0}   \n",
       "\n",
       "    mean_test_score  std_test_score  split0_test_score  split1_test_score  \\\n",
       "10         0.818750        0.026745           0.839583           0.827083   \n",
       "14         0.818750        0.027764           0.845833           0.831250   \n",
       "2          0.818333        0.024735           0.839583           0.831250   \n",
       "7          0.809167        0.023184           0.829167           0.804167   \n",
       "11         0.803750        0.025049           0.833333           0.822917   \n",
       "3          0.801250        0.028674           0.829167           0.829167   \n",
       "15         0.799167        0.027151           0.827083           0.825000   \n",
       "6          0.597917        0.055136           0.658333           0.668750   \n",
       "9          0.543750        0.087500           0.500000           0.500000   \n",
       "13         0.505000        0.010000           0.525000           0.500000   \n",
       "1          0.500417        0.000833           0.500000           0.502083   \n",
       "0          0.500000        0.000000           0.500000           0.500000   \n",
       "4          0.500000        0.000000           0.500000           0.500000   \n",
       "5          0.500000        0.000000           0.500000           0.500000   \n",
       "8          0.500000        0.000000           0.500000           0.500000   \n",
       "12         0.500000        0.000000           0.500000           0.500000   \n",
       "\n",
       "    split2_test_score  split3_test_score  split4_test_score  \n",
       "10           0.789583           0.785417           0.852083  \n",
       "14           0.787500           0.783333           0.845833  \n",
       "2            0.791667           0.785417           0.843750  \n",
       "7            0.779167           0.791667           0.841667  \n",
       "11           0.772917           0.775000           0.814583  \n",
       "3            0.758333           0.777083           0.812500  \n",
       "15           0.758333           0.777083           0.808333  \n",
       "6            0.556250           0.572917           0.533333  \n",
       "9            0.500000           0.718750           0.500000  \n",
       "13           0.500000           0.500000           0.500000  \n",
       "1            0.500000           0.500000           0.500000  \n",
       "0            0.500000           0.500000           0.500000  \n",
       "4            0.500000           0.500000           0.500000  \n",
       "5            0.500000           0.500000           0.500000  \n",
       "8            0.500000           0.500000           0.500000  \n",
       "12           0.500000           0.500000           0.500000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #MLP \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "mlp = MLPClassifier(max_iter=120)\n",
    "\n",
    "hyperparams = {\n",
    "    'activation': ['identity','logistic', 'relu', 'tanh'],\n",
    "    'alpha': 10.0 ** -np.arange(-2, 2)\n",
    "}\n",
    "\n",
    "clf_mlp = GridSearchCV(mlp, hyperparams, cv=5, verbose=0)\n",
    "clf_mlp.fit(x_train, y_train_df.values.ravel()) \n",
    "print(\"BEST SCORE: \")\n",
    "print(clf_mlp.best_score_)\n",
    "print(\"STANDARD DEVIATIONS\")\n",
    "print(clf_mlp.cv_results_['std_test_score'])\n",
    "print(\"STANDARD DEVIATION FOR BEST SCORE:\")\n",
    "print(clf_mlp.cv_results_['std_test_score'][clf_mlp.best_index_])\n",
    "\n",
    "df2 = pd.DataFrame(clf_mlp.cv_results_)\n",
    "df2[['rank_test_score','params', 'mean_test_score', 'std_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']].sort_values('rank_test_score')\n",
    "# pivot_mlp = pd.pivot_table(pd.DataFrame(clf_mlp.cv_results_), values='mean_test_score', index='param_hidden_layer_sizes', columns='param_activation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0cff81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2[['rank_test_score','params', 'mean_test_score', 'std_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f48821e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEST SCORE: \n",
      "0.7270833333333333\n",
      "STANDARD DEVIATIONS\n",
      "[0.02624008 0.02575256 0.03468609 0.04501157        nan        nan]\n",
      "STANDARD DEVIATION FOR BEST SCORE:\n",
      "0.0450115725860213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "10 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 352, in fit\n",
      "    criterion = CRITERIA_CLF[self.criterion](\n",
      "KeyError: 'log_loss'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/kali/miniconda3/envs/ml135_env_sp21/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.70291667 0.72083333 0.71875    0.72708333        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>{'criterion': 'entropy', 'splitter': 'random'}</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.683333</td>\n",
       "      <td>0.672917</td>\n",
       "      <td>0.727083</td>\n",
       "      <td>0.760417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>{'criterion': 'gini', 'splitter': 'random'}</td>\n",
       "      <td>0.720833</td>\n",
       "      <td>0.025753</td>\n",
       "      <td>0.756250</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.704167</td>\n",
       "      <td>0.697917</td>\n",
       "      <td>0.747917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>{'criterion': 'entropy', 'splitter': 'best'}</td>\n",
       "      <td>0.718750</td>\n",
       "      <td>0.034686</td>\n",
       "      <td>0.760417</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.747917</td>\n",
       "      <td>0.729167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>{'criterion': 'gini', 'splitter': 'best'}</td>\n",
       "      <td>0.702917</td>\n",
       "      <td>0.026240</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.691667</td>\n",
       "      <td>0.675000</td>\n",
       "      <td>0.681250</td>\n",
       "      <td>0.722917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>{'criterion': 'log_loss', 'splitter': 'best'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>{'criterion': 'log_loss', 'splitter': 'random'}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score                                           params  \\\n",
       "3                1   {'criterion': 'entropy', 'splitter': 'random'}   \n",
       "1                2      {'criterion': 'gini', 'splitter': 'random'}   \n",
       "2                3     {'criterion': 'entropy', 'splitter': 'best'}   \n",
       "0                4        {'criterion': 'gini', 'splitter': 'best'}   \n",
       "4                5    {'criterion': 'log_loss', 'splitter': 'best'}   \n",
       "5                6  {'criterion': 'log_loss', 'splitter': 'random'}   \n",
       "\n",
       "   mean_test_score  std_test_score  split0_test_score  split1_test_score  \\\n",
       "3         0.727083        0.045012           0.791667           0.683333   \n",
       "1         0.720833        0.025753           0.756250           0.697917   \n",
       "2         0.718750        0.034686           0.760417           0.681250   \n",
       "0         0.702917        0.026240           0.743750           0.691667   \n",
       "4              NaN             NaN                NaN                NaN   \n",
       "5              NaN             NaN                NaN                NaN   \n",
       "\n",
       "   split2_test_score  split3_test_score  split4_test_score  \n",
       "3           0.672917           0.727083           0.760417  \n",
       "1           0.704167           0.697917           0.747917  \n",
       "2           0.675000           0.747917           0.729167  \n",
       "0           0.675000           0.681250           0.722917  \n",
       "4                NaN                NaN                NaN  \n",
       "5                NaN                NaN                NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# SVM\n",
    "from sklearn import tree\n",
    "#from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "\n",
    "#svm = SVC(kernel='linear', C=100)\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# C = np.logspace(0, 6, 10)\n",
    "# kernels = ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed']\n",
    "# hyperparams = {\n",
    "#     'C': C,\n",
    "#     'kernel': kernels\n",
    "# }\n",
    "\n",
    "criterion = ['gini', 'entropy', 'log_loss']\n",
    "splitter = ['best', 'random']\n",
    "\n",
    "hyperparams = {\n",
    "    'criterion': criterion,\n",
    "    'splitter': splitter\n",
    "}\n",
    "\n",
    "clf_mlp = GridSearchCV(clf, hyperparams, cv=5, verbose=0)\n",
    "clf_mlp.fit(x_train, y_train_df.values.ravel()) \n",
    "print(\"BEST SCORE: \")\n",
    "print(clf_mlp.best_score_)\n",
    "print(\"STANDARD DEVIATIONS\")\n",
    "print(clf_mlp.cv_results_['std_test_score'])\n",
    "print(\"STANDARD DEVIATION FOR BEST SCORE:\")\n",
    "print(clf_mlp.cv_results_['std_test_score'][clf_mlp.best_index_])\n",
    "\n",
    "df3 = pd.DataFrame(clf_mlp.cv_results_)\n",
    "\n",
    "df3[['rank_test_score','params', 'mean_test_score', 'std_test_score', 'split0_test_score', 'split1_test_score', 'split2_test_score', 'split3_test_score', 'split4_test_score']].sort_values('rank_test_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec21f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv('LR.csv', index=False)\n",
    "df2.to_csv('nn.csv', index=False)\n",
    "df3.to_csv('dtree.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c5f15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OVERALL ACCURACY\n",
      ".81875\n",
      "AMAZON ACCURACY\n",
      "0.975\n",
      "YELP ACCURACY\n",
      "0.9775\n",
      "IMDB ACCURACY\n",
      "0.95875\n",
      "AMAZON TRUE POSITIVE\n",
      "0.97\n",
      "YELP TRUE POSITIVE\n",
      "0.965\n",
      "IMDB TRUE POSITIVE\n",
      "0.9425\n",
      "AMAZON TRUE NEGATIVE\n",
      "0.98\n",
      "YELP TRUE NEGATIVE\n",
      "0.99\n",
      "IMDB TRUE NEGATIVE\n",
      "0.975\n",
      "AMAZON FALSE POSITIVE\n",
      "0.03\n",
      "YELP FALSE POSITIVE\n",
      "0.035\n",
      "IMDB FALSE POSITIVE\n",
      "0.0575\n",
      "AMAZON FALSE NEGATIVE\n",
      "0.02\n",
      "YELP FALSE NEGATIVE\n",
      "0.01\n",
      "IMDB FALSE NEGATIVE\n",
      "0.025\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tr_web_list = x_train_df['website_name'].values.tolist()\n",
    "rst = clf_LR.predict(x_train)\n",
    "\n",
    "amazon_p = 0\n",
    "yelp_p = 0\n",
    "imdb_p = 0\n",
    "amazon_n = 0\n",
    "yelp_n = 0\n",
    "imdb_n = 0\n",
    "\n",
    "amazon_tp = 0\n",
    "yelp_tp = 0\n",
    "imdb_tp = 0\n",
    "amazon_tn = 0\n",
    "yelp_tn = 0\n",
    "imdb_tn = 0\n",
    "\n",
    "amazon_fp = 0\n",
    "yelp_fp = 0\n",
    "imdb_fp = 0\n",
    "amazon_fn = 0\n",
    "yelp_fn = 0\n",
    "imdb_fn = 0\n",
    "\n",
    "amazon_avg_rev = 0\n",
    "yelp_avg_rev = 0\n",
    "imdb_avg_rev = 0\n",
    "\n",
    "for i in range(0,2400):\n",
    "    if tr_web_list[i] == \"amazon\":\n",
    "        amazon_avg_rev+=x_train[i].shape[0]\n",
    "    elif tr_web_list[i] == \"yelp\":\n",
    "        yelp_avg_rev+=x_train[i].shape[0]\n",
    "    elif tr_web_list[i] == \"imdb\":\n",
    "        imdb_avg_rev+=x_train[i].shape[0]\n",
    "\n",
    "amazon_avg_rev = amazon_avg_rev/2400\n",
    "yelp_avg_rev = yelp_avg_rev/2400\n",
    "imdb_avg_rev = imdb_avg_rev/2400\n",
    "\n",
    "for i in range(0,2400):\n",
    "    if y_train_df.values[i] == 1 and tr_web_list[i] == \"amazon\":\n",
    "        amazon_p+=1\n",
    "    elif y_train_df.values[i] == 1 and tr_web_list[i] == \"yelp\":\n",
    "        yelp_p+=1\n",
    "    elif y_train_df.values[i] == 1 and tr_web_list[i] == \"imdb\":\n",
    "        imdb_p+=1\n",
    "    elif y_train_df.values[i] == 0 and tr_web_list[i] == \"amazon\":\n",
    "        amazon_n+=1\n",
    "    elif y_train_df.values[i] == 0 and tr_web_list[i] == \"yelp\":\n",
    "        yelp_n+=1\n",
    "    elif y_train_df.values[i] == 0 and tr_web_list[i] == \"imdb\":\n",
    "        imdb_n+=1\n",
    "\n",
    "for i in range(0,2400):\n",
    "    if rst[i] == 1 and y_train_df.values[i] == 1 and tr_web_list[i] == \"amazon\":\n",
    "        amazon_tp+=1\n",
    "    elif rst[i] == 1 and y_train_df.values[i] == 1 and tr_web_list[i] == \"yelp\":\n",
    "        yelp_tp+=1\n",
    "    elif rst[i] == 1 and y_train_df.values[i] == 1 and tr_web_list[i] == \"imdb\":\n",
    "        imdb_tp+=1\n",
    "    elif rst[i] == 0 and y_train_df.values[i] == 0 and tr_web_list[i] == \"amazon\":\n",
    "        amazon_tn+=1\n",
    "    elif rst[i] == 0 and y_train_df.values[i] == 0 and tr_web_list[i] == \"yelp\":\n",
    "        yelp_tn+=1\n",
    "    elif rst[i] == 0 and y_train_df.values[i] == 0 and tr_web_list[i] == \"imdb\":\n",
    "        imdb_tn+=1\n",
    "    elif rst[i] == 1 and y_train_df.values[i] == 0 and tr_web_list[i] == \"amazon\":\n",
    "        amazon_fn+=1\n",
    "    elif rst[i] == 1 and y_train_df.values[i] == 0 and tr_web_list[i] == \"yelp\":\n",
    "        yelp_fn+=1\n",
    "    elif rst[i] == 1 and y_train_df.values[i] == 0 and tr_web_list[i] == \"imdb\":\n",
    "        imdb_fn+=1\n",
    "    elif rst[i] == 0 and y_train_df.values[i] == 1 and tr_web_list[i] == \"amazon\":\n",
    "        amazon_fp+=1\n",
    "    elif rst[i] == 0 and y_train_df.values[i] == 1 and tr_web_list[i] == \"yelp\":\n",
    "        yelp_fp+=1\n",
    "    elif rst[i] == 0 and y_train_df.values[i] == 1 and tr_web_list[i] == \"imdb\":\n",
    "        imdb_fp+=1\n",
    "\n",
    "print(\"OVERALL ACCURACY\")\n",
    "print(\".81875\")\n",
    "print(\"AMAZON ACCURACY\")\n",
    "print(str((amazon_tp+amazon_tn)/(amazon_n+amazon_p)))\n",
    "print(\"YELP ACCURACY\")\n",
    "print(str((yelp_tp+yelp_tn)/(yelp_n+yelp_p)))\n",
    "print(\"IMDB ACCURACY\")\n",
    "print(str((imdb_tp+imdb_tn)/(imdb_n+imdb_p)))\n",
    "print(\"AMAZON TRUE POSITIVE\")\n",
    "print(str((amazon_tp)/(amazon_p)))\n",
    "print(\"YELP TRUE POSITIVE\")\n",
    "print(str((yelp_tp)/(yelp_p)))\n",
    "print(\"IMDB TRUE POSITIVE\")\n",
    "print(str((imdb_tp)/(imdb_p)))\n",
    "print(\"AMAZON TRUE NEGATIVE\")\n",
    "print(str((amazon_tn)/(amazon_n)))\n",
    "print(\"YELP TRUE NEGATIVE\")\n",
    "print(str((yelp_tn)/(yelp_n)))\n",
    "print(\"IMDB TRUE NEGATIVE\")\n",
    "print(str((imdb_tn)/(imdb_n)))\n",
    "print(\"AMAZON FALSE POSITIVE\")\n",
    "print(str((amazon_fp)/(amazon_p)))\n",
    "print(\"YELP FALSE POSITIVE\")\n",
    "print(str((yelp_fp)/(yelp_p)))\n",
    "print(\"IMDB FALSE POSITIVE\")\n",
    "print(str((imdb_fp)/(imdb_p)))\n",
    "print(\"AMAZON FALSE NEGATIVE\")\n",
    "print(str((amazon_fn)/(amazon_n)))\n",
    "print(\"YELP FALSE NEGATIVE\")\n",
    "print(str((yelp_fn)/(yelp_n)))\n",
    "print(\"IMDB FALSE NEGATIVE\")\n",
    "print(str((imdb_fn)/(imdb_n)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339a5735",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
